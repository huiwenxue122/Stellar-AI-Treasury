#!/usr/bin/env python3
"""
Thompsoné‡‡æ ·é€‰æ‹©å™¨
åŸºäºçº¿æ€§é«˜æ–¯åéªŒçš„Contextual Thompson Sampling
"""

import numpy as np
import pandas as pd
from typing import List, Dict, Any, Optional, Tuple
import pickle
import os
from dataclasses import dataclass
import warnings
warnings.filterwarnings('ignore')

@dataclass
class ThompsonSelectorConfig:
    """Thompsoné€‰æ‹©å™¨é…ç½®"""
    alpha: float = 1.0          # å™ªå£°å‚æ•°
    beta: float = 1.0           # æ­£åˆ™åŒ–å‚æ•°
    n_arms: int = 10           # è‡‚æ•°ï¼ˆç­–ç•¥æ•°ï¼‰
    n_features: int = 50       # ç‰¹å¾ç»´åº¦
    warmup_samples: int = 100  # é¢„çƒ­æ ·æœ¬æ•°
    update_frequency: int = 10 # æ›´æ–°é¢‘ç‡

class ThompsonSelector:
    """Thompsoné‡‡æ ·é€‰æ‹©å™¨"""
    
    def __init__(self, config: ThompsonSelectorConfig):
        self.config = config
        self.n_arms = config.n_arms
        self.n_features = config.n_features
        
        # åˆå§‹åŒ–åéªŒå‚æ•°
        self.mu = np.zeros((self.n_arms, self.n_features))  # å‡å€¼
        self.Sigma = np.array([np.eye(self.n_features) for _ in range(self.n_arms)])  # åæ–¹å·®
        self.b = np.zeros((self.n_arms, self.n_features))   # ç´¯ç§¯å¥–åŠ±
        self.A = np.array([np.eye(self.n_features) for _ in range(self.n_arms)])  # ç´¯ç§¯ç‰¹å¾
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.n_pulls = np.zeros(self.n_arms)  # æ¯ä¸ªè‡‚çš„æ‹‰åŠ¨æ¬¡æ•°
        self.total_rewards = np.zeros(self.n_arms)  # æ€»å¥–åŠ±
        self.arm_rewards = [[] for _ in range(self.n_arms)]  # æ¯ä¸ªè‡‚çš„å¥–åŠ±å†å²
        
        # çŠ¶æ€
        self.is_initialized = False
        self.update_count = 0
    
    def pick(self, x: np.ndarray, topk: int = 2) -> List[int]:
        """
        é€‰æ‹©top-kç­–ç•¥
        
        Args:
            x: æƒ…å¢ƒç‰¹å¾å‘é‡
            topk: è¿”å›çš„ç­–ç•¥æ•°é‡
            
        Returns:
            é€‰æ‹©çš„ç­–ç•¥ç´¢å¼•åˆ—è¡¨
        """
        if not self.is_initialized:
            # å¦‚æœæœªåˆå§‹åŒ–ï¼Œéšæœºé€‰æ‹©
            return np.random.choice(self.n_arms, size=min(topk, self.n_arms), replace=False).tolist()
        
        # è®¡ç®—æ¯ä¸ªè‡‚çš„é‡‡æ ·å€¼
        sampled_values = []
        for arm in range(self.n_arms):
            # ä»åéªŒåˆ†å¸ƒé‡‡æ ·
            theta = np.random.multivariate_normal(self.mu[arm], self.Sigma[arm])
            sampled_value = np.dot(theta, x)
            sampled_values.append(sampled_value)
        
        # é€‰æ‹©top-k
        top_arms = np.argsort(sampled_values)[-topk:][::-1]
        return top_arms.tolist()
    
    def update(self, x: np.ndarray, k: int, reward: float):
        """
        æ›´æ–°åéªŒåˆ†å¸ƒ
        
        Args:
            x: æƒ…å¢ƒç‰¹å¾å‘é‡
            k: é€‰æ‹©çš„ç­–ç•¥ç´¢å¼•
            reward: è§‚å¯Ÿåˆ°çš„å¥–åŠ±
        """
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.n_pulls[k] += 1
        self.total_rewards[k] += reward
        self.arm_rewards[k].append(reward)
        
        # æ›´æ–°åéªŒå‚æ•°
        self.b[k] += reward * x
        self.A[k] += np.outer(x, x)
        
        # æ›´æ–°åæ–¹å·®çŸ©é˜µ
        self.Sigma[k] = np.linalg.inv(self.A[k] + self.config.beta * np.eye(self.n_features))
        
        # æ›´æ–°å‡å€¼
        self.mu[k] = self.Sigma[k] @ self.b[k]
        
        self.update_count += 1
        
        # æ£€æŸ¥æ˜¯å¦åˆå§‹åŒ–
        if not self.is_initialized and self.update_count >= self.config.warmup_samples:
            self.is_initialized = True
    
    def get_arm_stats(self) -> Dict[str, Any]:
        """è·å–è‡‚ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        for arm in range(self.n_arms):
            if self.n_pulls[arm] > 0:
                stats[f'arm_{arm}'] = {
                    'n_pulls': self.n_pulls[arm],
                    'total_reward': self.total_rewards[arm],
                    'avg_reward': self.total_rewards[arm] / self.n_pulls[arm],
                    'reward_std': np.std(self.arm_rewards[arm]) if len(self.arm_rewards[arm]) > 1 else 0
                }
        return stats
    
    def get_confidence_bounds(self, x: np.ndarray, confidence: float = 0.95) -> Dict[int, Tuple[float, float]]:
        """
        è·å–ç½®ä¿¡åŒºé—´
        
        Args:
            x: æƒ…å¢ƒç‰¹å¾å‘é‡
            confidence: ç½®ä¿¡æ°´å¹³
            
        Returns:
            æ¯ä¸ªè‡‚çš„ç½®ä¿¡åŒºé—´
        """
        bounds = {}
        z_score = 1.96 if confidence == 0.95 else 2.576  # 95% or 99%
        
        for arm in range(self.n_arms):
            if self.n_pulls[arm] > 0:
                # è®¡ç®—é¢„æµ‹å‡å€¼å’Œæ–¹å·®
                mean_pred = np.dot(self.mu[arm], x)
                var_pred = np.dot(x, self.Sigma[arm] @ x)
                std_pred = np.sqrt(var_pred)
                
                # ç½®ä¿¡åŒºé—´
                lower = mean_pred - z_score * std_pred
                upper = mean_pred + z_score * std_pred
                
                bounds[arm] = (lower, upper)
        
        return bounds
    
    def get_expected_rewards(self, x: np.ndarray) -> Dict[int, float]:
        """
        è·å–æœŸæœ›å¥–åŠ±
        
        Args:
            x: æƒ…å¢ƒç‰¹å¾å‘é‡
            
        Returns:
            æ¯ä¸ªè‡‚çš„æœŸæœ›å¥–åŠ±
        """
        expected_rewards = {}
        for arm in range(self.n_arms):
            if self.n_pulls[arm] > 0:
                expected_rewards[arm] = np.dot(self.mu[arm], x)
            else:
                expected_rewards[arm] = 0.0
        
        return expected_rewards
    
    def get_arm_rankings(self, x: np.ndarray) -> List[Tuple[int, float]]:
        """
        è·å–è‡‚æ’å
        
        Args:
            x: æƒ…å¢ƒç‰¹å¾å‘é‡
            
        Returns:
            æŒ‰æœŸæœ›å¥–åŠ±æ’åºçš„è‡‚åˆ—è¡¨
        """
        expected_rewards = self.get_expected_rewards(x)
        rankings = sorted(expected_rewards.items(), key=lambda x: x[1], reverse=True)
        return rankings
    
    def save_state(self, filepath: str):
        """ä¿å­˜çŠ¶æ€"""
        state = {
            'config': self.config,
            'mu': self.mu,
            'Sigma': self.Sigma,
            'b': self.b,
            'A': self.A,
            'n_pulls': self.n_pulls,
            'total_rewards': self.total_rewards,
            'arm_rewards': self.arm_rewards,
            'is_initialized': self.is_initialized,
            'update_count': self.update_count
        }
        
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        with open(filepath, 'wb') as f:
            pickle.dump(state, f)
    
    def load_state(self, filepath: str):
        """åŠ è½½çŠ¶æ€"""
        if os.path.exists(filepath):
            with open(filepath, 'rb') as f:
                state = pickle.load(f)
            
            self.config = state['config']
            self.mu = state['mu']
            self.Sigma = state['Sigma']
            self.b = state['b']
            self.A = state['A']
            self.n_pulls = state['n_pulls']
            self.total_rewards = state['total_rewards']
            self.arm_rewards = state['arm_rewards']
            self.is_initialized = state['is_initialized']
            self.update_count = state['update_count']
        else:
            print(f"çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
    
    def reset(self):
        """é‡ç½®é€‰æ‹©å™¨"""
        self.mu = np.zeros((self.n_arms, self.n_features))
        self.Sigma = np.array([np.eye(self.n_features) for _ in range(self.n_arms)])
        self.b = np.zeros((self.n_arms, self.n_features))
        self.A = np.array([np.eye(self.n_features) for _ in range(self.n_arms)])
        self.n_pulls = np.zeros(self.n_arms)
        self.total_rewards = np.zeros(self.n_arms)
        self.arm_rewards = [[] for _ in range(self.n_arms)]
        self.is_initialized = False
        self.update_count = 0
    
    def get_info(self) -> Dict[str, Any]:
        """è·å–é€‰æ‹©å™¨ä¿¡æ¯"""
        return {
            'config': self.config,
            'n_arms': self.n_arms,
            'n_features': self.n_features,
            'is_initialized': self.is_initialized,
            'update_count': self.update_count,
            'total_pulls': np.sum(self.n_pulls),
            'arm_stats': self.get_arm_stats()
        }

class LinUCBSelector:
    """LinUCBé€‰æ‹©å™¨ï¼ˆä½œä¸ºå¯¹æ¯”ï¼‰"""
    
    def __init__(self, config: ThompsonSelectorConfig):
        self.config = config
        self.n_arms = config.n_arms
        self.n_features = config.n_features
        
        # åˆå§‹åŒ–å‚æ•°
        self.mu = np.zeros((self.n_arms, self.n_features))
        self.A = np.array([np.eye(self.n_features) for _ in range(self.n_arms)])
        self.b = np.zeros((self.n_arms, self.n_features))
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.n_pulls = np.zeros(self.n_arms)
        self.total_rewards = np.zeros(self.n_arms)
    
    def pick(self, x: np.ndarray, topk: int = 2) -> List[int]:
        """é€‰æ‹©top-kç­–ç•¥"""
        ucb_values = []
        
        for arm in range(self.n_arms):
            if self.n_pulls[arm] == 0:
                ucb_values.append(float('inf'))
            else:
                # è®¡ç®—UCBå€¼
                mean_pred = np.dot(self.mu[arm], x)
                var_pred = np.dot(x, self.A[arm] @ x)
                ucb_value = mean_pred + self.config.alpha * np.sqrt(var_pred)
                ucb_values.append(ucb_value)
        
        # é€‰æ‹©top-k
        top_arms = np.argsort(ucb_values)[-topk:][::-1]
        return top_arms.tolist()
    
    def update(self, x: np.ndarray, k: int, reward: float):
        """æ›´æ–°å‚æ•°"""
        self.n_pulls[k] += 1
        self.total_rewards[k] += reward
        
        self.b[k] += reward * x
        self.A[k] += np.outer(x, x)
        
        # æ›´æ–°å‡å€¼
        self.mu[k] = np.linalg.solve(self.A[k], self.b[k])

def create_selector(selector_type: str = 'thompson', config: Optional[ThompsonSelectorConfig] = None) -> Any:
    """
    åˆ›å»ºé€‰æ‹©å™¨
    
    Args:
        selector_type: é€‰æ‹©å™¨ç±»å‹ ('thompson' or 'linucb')
        config: é…ç½®å‚æ•°
        
    Returns:
        é€‰æ‹©å™¨å®ä¾‹
    """
    if config is None:
        config = ThompsonSelectorConfig()
    
    if selector_type == 'thompson':
        return ThompsonSelector(config)
    elif selector_type == 'linucb':
        return LinUCBSelector(config)
    else:
        raise ValueError(f"æœªçŸ¥çš„é€‰æ‹©å™¨ç±»å‹: {selector_type}")

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºé€‰æ‹©å™¨"""
    print("ğŸš€ Thompsoné‡‡æ ·é€‰æ‹©å™¨æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºé…ç½®
    config = ThompsonSelectorConfig(
        n_arms=5,
        n_features=10,
        alpha=1.0,
        beta=1.0
    )
    
    # åˆ›å»ºé€‰æ‹©å™¨
    selector = ThompsonSelector(config)
    
    print(f"ğŸ“Š é€‰æ‹©å™¨é…ç½®:")
    print(f"  è‡‚æ•°: {config.n_arms}")
    print(f"  ç‰¹å¾ç»´åº¦: {config.n_features}")
    print(f"  å™ªå£°å‚æ•°: {config.alpha}")
    print(f"  æ­£åˆ™åŒ–å‚æ•°: {config.beta}")
    
    # æ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    n_samples = 1000
    
    print(f"\nğŸ”„ æ¨¡æ‹Ÿè®­ç»ƒ: {n_samples} ä¸ªæ ·æœ¬")
    
    for i in range(n_samples):
        # ç”Ÿæˆéšæœºç‰¹å¾
        x = np.random.randn(config.n_features)
        
        # é€‰æ‹©ç­–ç•¥
        if i < 50:  # å‰50ä¸ªæ ·æœ¬éšæœºé€‰æ‹©
            k = np.random.randint(0, config.n_arms)
        else:
            selected_arms = selector.pick(x, topk=1)
            k = selected_arms[0]
        
        # ç”Ÿæˆå¥–åŠ±
        true_reward = np.dot(x[:3], [1, -0.5, 0.3]) + np.random.normal(0, 0.1)
        reward = true_reward + np.random.normal(0, 0.05)
        
        # æ›´æ–°é€‰æ‹©å™¨
        selector.update(x, k, reward)
        
        if i % 100 == 0:
            print(f"  æ ·æœ¬ {i}: é€‰æ‹©è‡‚ {k}, å¥–åŠ± {reward:.3f}")
    
    # æ˜¾ç¤ºç»“æœ
    print(f"\nğŸ“Š è®­ç»ƒç»“æœ:")
    stats = selector.get_arm_stats()
    for arm, stat in stats.items():
        print(f"  {arm}: æ‹‰åŠ¨æ¬¡æ•° {stat['n_pulls']}, å¹³å‡å¥–åŠ± {stat['avg_reward']:.3f}")
    
    # æµ‹è¯•é€‰æ‹©
    print(f"\nğŸ¯ æµ‹è¯•é€‰æ‹©:")
    test_x = np.random.randn(config.n_features)
    selected_arms = selector.pick(test_x, topk=3)
    print(f"  ç‰¹å¾å‘é‡: {test_x[:5]}...")
    print(f"  é€‰æ‹©çš„è‡‚: {selected_arms}")
    
    # è·å–æœŸæœ›å¥–åŠ±
    expected_rewards = selector.get_expected_rewards(test_x)
    print(f"  æœŸæœ›å¥–åŠ±: {expected_rewards}")
    
    # è·å–è‡‚æ’å
    rankings = selector.get_arm_rankings(test_x)
    print(f"  è‡‚æ’å: {rankings}")
    
    # ä¿å­˜çŠ¶æ€
    selector.save_state('artifacts/selector_state.pkl')
    print(f"\nğŸ’¾ çŠ¶æ€å·²ä¿å­˜: artifacts/selector_state.pkl")
    
    # åŠ è½½çŠ¶æ€æµ‹è¯•
    new_selector = ThompsonSelector(config)
    new_selector.load_state('artifacts/selector_state.pkl')
    print(f"âœ… çŠ¶æ€åŠ è½½æˆåŠŸ")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ é€‰æ‹©å™¨æ¼”ç¤ºå®Œæˆï¼")

if __name__ == "__main__":
    main()
