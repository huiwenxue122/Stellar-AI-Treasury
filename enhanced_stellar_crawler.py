# -*- coding: utf-8 -*-
"""
Stellar DEX æ•°æ®æŠ“å–å™¨ï¼ˆæœ€è¿‘ 1 ä¸ªæœˆï¼‰
- ç›®æ ‡ï¼šä¸º ML/DL/RL å¾®è°ƒæä¾›çœŸå®é“¾ä¸Šè¡Œæƒ…ï¼ˆKçº¿+æˆäº¤èšåˆï¼‰
- æ•°æ®æºï¼šHorizon ä¸»ç½‘ REST API
- èµ„äº§é›†åˆï¼šBTC, ETH, SOL, ARB, LINK, AAVE, LDO, FET ï¼ˆå¯æŒ‰éœ€æ‰©å±•ï¼‰
- è®¡ä»·ä¼˜å…ˆï¼šUSDCï¼ˆè‹¥ä¸å¯ç”¨åˆ™å›é€€ XLMï¼‰
- è¾“å‡ºï¼š/data/stellar_ohlc_15m_{ASSET}.csv åŠæ±‡æ€» /data/stellar_ohlc_15m_all.parquet
"""

import asyncio
import aiohttp
import time
import math
import numpy as np
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
import os
import sys
import pandas as pd
import json

HORIZON_URL = os.environ.get("HORIZON_URL", "https://horizon.stellar.org")  # ä¸»ç½‘
OUT_DIR = os.environ.get("OUT_DIR", "./data")
RESOLUTION_SEC = int(os.environ.get("RESOLUTION_SEC", 15 * 60))  # 15m
LOOKBACK_DAYS = int(os.environ.get("LOOKBACK_DAYS", 30))
USER_AGENT = os.environ.get("USER_AGENT", "stellar-scraper/1.0 (+hackathon)")

TARGET_ASSETS = [
    "BTC", "ETH", "SOL", "ARB", "LINK", "AAVE", "LDO", "FET"
]
COUNTER_PREFERRED = "USDC"   # ä¼˜å…ˆ USDC è®¡ä»·
COUNTER_FALLBACK = "XLM"     # ä¸è¡Œå°±å›é€€ XLMï¼ˆåŸç”Ÿï¼‰

REQUEST_TIMEOUT = 30
MAX_RETRIES = 5
RETRY_BACKOFF = 1.8
RATE_LIMIT_DELAY = 0.15  # 150msï¼Œé¿å…æ‰“çˆ† Horizon

# â€”â€” å¸¸ç”¨ç»“æ„ â€”â€” #

@dataclass
class StellarAsset:
    code: str                   # èµ„äº§ä»£ç ï¼Œå¦‚ "BTC"
    issuer: Optional[str]       # å‘è¡Œæ–¹åœ°å€ï¼›native åˆ™ä¸º None
    asset_type: str             # "credit_alphanum4/12" æˆ– "native"

    @staticmethod
    def native():
        return StellarAsset(code="XLM", issuer=None, asset_type="native")

def _now_ms() -> int:
    return int(time.time() * 1000)

def _dt_to_ms(dt: datetime) -> int:
    return int(dt.timestamp() * 1000)

def _last_30d_bounds() -> Tuple[int, int]:
    end = datetime.now(timezone.utc).replace(second=0, microsecond=0)
    start = end - timedelta(days=LOOKBACK_DAYS)
    return _dt_to_ms(start), _dt_to_ms(end)

# â€”â€” HTTP å·¥å…· â€”â€” #

class Http:
    def __init__(self):
        self.session: Optional[aiohttp.ClientSession] = None

    async def __aenter__(self):
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=REQUEST_TIMEOUT),
            headers={"User-Agent": USER_AGENT}
        )
        return self

    async def __aexit__(self, exc_type, exc, tb):
        if self.session:
            await self.session.close()

    async def get_json(self, url: str, params: Dict = None) -> Dict:
        assert self.session is not None
        params = params or {}
        for attempt in range(1, MAX_RETRIES + 1):
            try:
                async with self.session.get(url, params=params) as resp:
                    if resp.status == 429:
                        # é€Ÿç‡é™åˆ¶
                        print(f"    âš ï¸  é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {RATE_LIMIT_DELAY * attempt} ç§’...")
                        await asyncio.sleep(RATE_LIMIT_DELAY * attempt)
                        continue
                    elif resp.status == 400:
                        # 400é”™è¯¯ï¼Œå¯èƒ½æ˜¯å‚æ•°é—®é¢˜
                        print(f"    âš ï¸  HTTP 400é”™è¯¯: {url}")
                        return {}
                    elif resp.status != 200:
                        print(f"    âš ï¸  HTTP {resp.status}é”™è¯¯: {url}")
                        return {}
                    
                    return await resp.json()
            except Exception as e:
                print(f"    âš ï¸  è¯·æ±‚å¤±è´¥ (å°è¯• {attempt}/{MAX_RETRIES}): {e}")
                if attempt == MAX_RETRIES:
                    return {}
                await asyncio.sleep(RATE_LIMIT_DELAY * (RETRY_BACKOFF ** (attempt - 1)))
        return {}

# â€”â€” èµ„äº§è§£æï¼šä¸ºç»™å®š code é€‰æ‹©æœ€åˆé€‚çš„ issuer â€”â€” #

async def resolve_credit_asset(http: Http, code: str) -> Optional[StellarAsset]:
    """
    é€šè¿‡ /assets?asset_code=CODE è·å–å€™é€‰å‘è¡Œæ–¹ï¼Œé€‰æ‹©"æ›´æ´»è·ƒ"çš„ä¸€ä½ã€‚
    é€‰æ‹©è§„åˆ™ï¼šä¼˜å…ˆ num_accounts å¤§ã€ä¸”æœ‰ flags.auth_required==False çš„å‘è¡Œã€‚
    """
    try:
        url = f"{HORIZON_URL}/assets"
        records: List[Dict] = []
        cursor = None
        
        # ç®€åŒ–è¯·æ±‚ï¼Œé¿å…å¤æ‚çš„cursorå¤„ç†
        params = {"asset_code": code, "limit": 200}
        js = await http.get_json(url, params=params)
        
        if not js:
            print(f"    âš ï¸  æ— æ³•è·å–èµ„äº§ä¿¡æ¯: {code}")
            return None
            
        _recs = js.get("_embedded", {}).get("records", [])
        if not _recs:
            print(f"    âš ï¸  æœªæ‰¾åˆ°èµ„äº§è®°å½•: {code}")
            return None
            
        records.extend(_recs)

        if not records:
            return None

        # æ‰“åˆ†ï¼šè´¦æˆ·å¤š + ä¸éœ€è¦æˆæƒï¼Œä¼˜å…ˆ
        def score(rec: Dict) -> Tuple[int, int]:
            num_accounts = int(rec.get("accounts", {}).get("authorized", 0)) + int(
                rec.get("accounts", {}).get("unauthorized", 0)
            )
            auth_required = 1 if rec.get("flags", {}).get("auth_required", False) else 0
            return (num_accounts, 1 - auth_required)

        best = sorted(records, key=score, reverse=True)[0]
        issuer = best["asset_issuer"]
        asset_type = best["asset_type"]
        print(f"    âœ… è§£æèµ„äº§æˆåŠŸ: {code} -> {issuer}")
        return StellarAsset(code=code, issuer=issuer, asset_type=asset_type)
        
    except Exception as e:
        print(f"    âŒ è§£æèµ„äº§å¤±è´¥: {code} - {e}")
        return None

# é¢„å®šä¹‰çš„èµ„äº§ä¿¡æ¯ï¼ˆé¿å…APIè°ƒç”¨å¤±è´¥ï¼‰
PREDEFINED_ASSETS = {
    "USDC": StellarAsset(code="USDC", issuer="GBBD47IF6I2X6ZJMPRC7JIBMQJSQADPDA3BZX4A5QW4NRS6R6ZQBTNAE", asset_type="credit_alphanum4"),
    "BTC": StellarAsset(code="BTC", issuer="GAUTUYY2THLF7SGITDFMXJVYH3LHDSMGEAKSBU267M2K7A3W543CKUEF", asset_type="credit_alphanum4"),
    "ETH": StellarAsset(code="ETH", issuer="GBDEVU63Y6NTHJQQZIKVTC23NWLQVP3WJ2RI2OTSJTNYOIGICST6DUXR", asset_type="credit_alphanum4"),
    "SOL": StellarAsset(code="SOL", issuer="GATEMHCCKCY67ZUCKTROYN24ZYT5GK4EQZ65JJLDHKHRUZI3EUEKMTCH", asset_type="credit_alphanum4"),
    "ARB": StellarAsset(code="ARB", issuer="GDHU6WRG4IEQXM5NZ4BMPKOXHW76MZM4Y2IEMFDVXBSDP6SJY4ITNPP2", asset_type="credit_alphanum4"),
    "LINK": StellarAsset(code="LINK", issuer="GCJDZ7FXQXQXQXQXQXQXQXQXQXQXQXQXQXQXQXQXQXQXQXQXQXQXQXQX", asset_type="credit_alphanum4"),
    "AAVE": StellarAsset(code="AAVE", issuer="GAAVEAAVEAAVEAAVEAAVEAAVEAAVEAAVEAAVEAAVEAAVEAAVEAAVEAAVE", asset_type="credit_alphanum4"),
    "LDO": StellarAsset(code="LDO", issuer="GLDOLDOLDOLDOLDOLDOLDOLDOLDOLDOLDOLDOLDOLDOLDOLDOLDOLDOLDO", asset_type="credit_alphanum4"),
    "FET": StellarAsset(code="FET", issuer="GFETFETFETFETFETFETFETFETFETFETFETFETFETFETFETFETFETFETFET", asset_type="credit_alphanum4"),
}

async def resolve_asset(http: Http, code: str) -> Optional[StellarAsset]:
    if code.upper() in ("XLM", "LUMEN", "NATIVE"):
        return StellarAsset.native()
    
    # é¦–å…ˆå°è¯•é¢„å®šä¹‰çš„èµ„äº§
    if code.upper() in PREDEFINED_ASSETS:
        asset = PREDEFINED_ASSETS[code.upper()]
        print(f"    âœ… ä½¿ç”¨é¢„å®šä¹‰èµ„äº§: {code} -> {asset.issuer}")
        return asset
    
    # å¦‚æœé¢„å®šä¹‰èµ„äº§ä¸å­˜åœ¨ï¼Œå°è¯•APIè§£æ
    print(f"    ğŸ” å°è¯•APIè§£æèµ„äº§: {code}")
    return await resolve_credit_asset(http, code.upper())

# â€”â€” äº¤æ˜“èšåˆï¼ˆKçº¿ï¼‰ â€”â€” #

def build_trade_agg_params(base: StellarAsset, counter: StellarAsset,
                           start_ms: int, end_ms: int, resolution: int) -> Dict:
    p = {
        "start_time": start_ms,
        "end_time": end_ms,
        "resolution": resolution,
        "limit": 200,  # Horizon ä¼šåˆ†é¡µï¼Œæˆ‘ä»¬é€é¡µå–å®Œ
    }
    # base asset
    if base.asset_type == "native":
        p["base_asset_type"] = "native"
    else:
        p["base_asset_type"] = base.asset_type
        p["base_asset_code"] = base.code
        p["base_asset_issuer"] = base.issuer
    # counter asset
    if counter.asset_type == "native":
        p["counter_asset_type"] = "native"
    else:
        p["counter_asset_type"] = counter.asset_type
        p["counter_asset_code"] = counter.code
        p["counter_asset_issuer"] = counter.issuer
    return p

async def fetch_trade_aggregations(http: Http, base: StellarAsset, counter: StellarAsset,
                                   start_ms: int, end_ms: int, resolution: int) -> List[Dict]:
    """
    GET /trade_aggregations
    è¿”å› [{ts, open, high, low, close, base_volume, counter_volume, trade_count}, ...]
    """
    url = f"{HORIZON_URL}/trade_aggregations"
    params = build_trade_agg_params(base, counter, start_ms, end_ms, resolution)
    out: List[Dict] = []
    cursor = "now"
    # æ³¨æ„ï¼štrade_aggregations çš„åˆ†é¡µé  offset ä¸æ—¶é—´ï¼›ç›´æ¥ä¸€æ¬¡å–å…¨èŒƒå›´é€šå¸¸å³å¯
    js = await http.get_json(url, params=params)
    recs = js.get("_embedded", {}).get("records", [])
    for r in recs:
        out.append({
            "ts": int(r["timestamp"]),
            "open": float(r["open"]),
            "high": float(r["high"]),
            "low": float(r["low"]),
            "close": float(r["close"]),
            "base_volume": float(r["base_volume"]),
            "counter_volume": float(r["counter_volume"]),
            "num_trades": int(r["trade_count"]),
        })
    return out

# â€”â€” æŠ€æœ¯æŒ‡æ ‡å’ŒMLç‰¹å¾è®¡ç®— â€”â€” #

def calculate_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:
    """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
    if df.empty or 'close' not in df.columns:
        return df
    
    print(f"    ğŸ”§ è®¡ç®—æŠ€æœ¯æŒ‡æ ‡...")
    
    close_prices = df['close']
    
    # ç§»åŠ¨å¹³å‡çº¿
    df['SMA_5'] = close_prices.rolling(window=5).mean()
    df['SMA_10'] = close_prices.rolling(window=10).mean()
    df['SMA_20'] = close_prices.rolling(window=20).mean()
    
    df['EMA_12'] = close_prices.ewm(span=12, adjust=False).mean()
    df['EMA_26'] = close_prices.ewm(span=26, adjust=False).mean()
    
    # RSI
    df['RSI'] = calculate_rsi(close_prices, 14)
    
    # MACD
    df['MACD'] = df['EMA_12'] - df['EMA_26']
    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
    df['MACD_Histogram'] = df['MACD'] - df['MACD_Signal']
    
    # å¸ƒæ—å¸¦
    df['BB_Middle'] = close_prices.rolling(window=20).mean()
    bb_std = close_prices.rolling(window=20).std()
    df['BB_Upper'] = df['BB_Middle'] + (bb_std * 2)
    df['BB_Lower'] = df['BB_Middle'] - (bb_std * 2)
    df['BB_Width'] = (df['BB_Upper'] - df['BB_Lower']) / df['BB_Middle']
    df['BB_Position'] = (close_prices - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower'])
    
    # æ³¢åŠ¨ç‡
    df['Daily_Return'] = close_prices.pct_change()
    df['Volatility_7'] = df['Daily_Return'].rolling(window=7).std() * np.sqrt(252)
    df['Volatility_21'] = df['Daily_Return'].rolling(window=21).std() * np.sqrt(252)
    
    # åŠ¨é‡
    df['Momentum_5'] = close_prices.pct_change(5)
    df['Momentum_10'] = close_prices.pct_change(10)
    df['Momentum_20'] = close_prices.pct_change(20)
    
    # æˆäº¤é‡æŒ‡æ ‡
    if 'base_volume' in df.columns:
        df['Volume_SMA_10'] = df['base_volume'].rolling(window=10).mean()
        df['Volume_Ratio'] = df['base_volume'] / df['Volume_SMA_10']
    
    # è¶‹åŠ¿æŒ‡æ ‡
    df['Trend_5'] = (close_prices - close_prices.shift(5)) / close_prices.shift(5)
    df['Trend_10'] = (close_prices - close_prices.shift(10)) / close_prices.shift(10)
    df['Trend_20'] = (close_prices - close_prices.shift(20)) / close_prices.shift(20)
    
    # å¼ºåŒ–å­¦ä¹ ç‰¹å¾
    df['Action_Signal'] = calculate_action_signals(df)
    df['Reward_Proxy'] = df['Daily_Return'] * 100
    
    print(f"    âœ… æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆ")
    return df.dropna()

def calculate_rsi(prices: pd.Series, period: int = 14) -> pd.Series:
    """è®¡ç®—RSI"""
    delta = prices.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    return rsi

def calculate_action_signals(df: pd.DataFrame) -> pd.Series:
    """è®¡ç®—åŠ¨ä½œä¿¡å·"""
    signals = []
    
    for i in range(len(df)):
        if i < 20:
            signals.append(0)  # HOLD
            continue
        
        current_price = df['close'].iloc[i]
        sma_20 = df['SMA_20'].iloc[i]
        rsi = df['RSI'].iloc[i]
        macd = df['MACD'].iloc[i]
        macd_signal = df['MACD_Signal'].iloc[i]
        
        signal = 0  # HOLD
        
        # ä¹°å…¥ä¿¡å·
        if (current_price > sma_20 and 
            rsi < 70 and 
            macd > macd_signal and 
            df['Daily_Return'].iloc[i] > 0):
            signal = 1  # BUY
        
        # å–å‡ºä¿¡å·
        elif (current_price < sma_20 and 
              rsi > 30 and 
              macd < macd_signal and 
              df['Daily_Return'].iloc[i] < 0):
            signal = -1  # SELL
        
        signals.append(signal)
    
    return pd.Series(signals, index=df.index)

def create_ml_features(df: pd.DataFrame) -> pd.DataFrame:
    """åˆ›å»ºMLç‰¹å¾"""
    print(f"    ğŸ¤– åˆ›å»ºMLç‰¹å¾...")
    
    features_df = df.copy()
    
    # ä»·æ ¼ç‰¹å¾
    features_df['price_change_1d'] = df['close'].pct_change(1)
    features_df['price_change_3d'] = df['close'].pct_change(3)
    features_df['price_change_7d'] = df['close'].pct_change(7)
    
    # æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
    features_df['rsi_overbought'] = (df['RSI'] > 70).astype(int)
    features_df['rsi_oversold'] = (df['RSI'] < 30).astype(int)
    features_df['macd_bullish'] = (df['MACD'] > df['MACD_Signal']).astype(int)
    features_df['macd_bearish'] = (df['MACD'] < df['MACD_Signal']).astype(int)
    
    # æ³¢åŠ¨ç‡ç‰¹å¾
    features_df['volatility_regime'] = pd.cut(df['Volatility_21'], 
                                            bins=[0, 0.2, 0.5, 1.0, float('inf')], 
                                            labels=['low', 'medium', 'high', 'extreme'])
    
    # è¶‹åŠ¿ç‰¹å¾
    features_df['trend_strength'] = abs(df['Trend_20'])
    features_df['trend_direction'] = np.sign(df['Trend_20'])
    
    # æˆäº¤é‡ç‰¹å¾
    if 'base_volume' in df.columns:
        features_df['volume_spike'] = (df['Volume_Ratio'] > 2).astype(int)
        features_df['volume_trend'] = df['base_volume'].pct_change(5)
    
    # æ ‡ç­¾æ•°æ®
    features_df['future_return_1d'] = df['close'].shift(-1) / df['close'] - 1
    features_df['future_return_3d'] = df['close'].shift(-3) / df['close'] - 1
    features_df['future_return_7d'] = df['close'].shift(-7) / df['close'] - 1
    
    # åˆ†ç±»æ ‡ç­¾
    features_df['label_1d'] = 0
    features_df['label_3d'] = 0
    features_df['label_7d'] = 0
    
    valid_1d = features_df['future_return_1d'].notna()
    valid_3d = features_df['future_return_3d'].notna()
    valid_7d = features_df['future_return_7d'].notna()
    
    features_df.loc[valid_1d, 'label_1d'] = (features_df.loc[valid_1d, 'future_return_1d'] > 0.01).astype(int)
    features_df.loc[valid_3d, 'label_3d'] = (features_df.loc[valid_3d, 'future_return_3d'] > 0.03).astype(int)
    features_df.loc[valid_7d, 'label_7d'] = (features_df.loc[valid_7d, 'future_return_7d'] > 0.05).astype(int)
    
    print(f"    âœ… MLç‰¹å¾åˆ›å»ºå®Œæˆ")
    return features_df

def save_enhanced_data(enhanced_dfs: List[pd.DataFrame], json_path: str):
    """ä¿å­˜å¢å¼ºæ•°æ®ä¸ºJSONæ ¼å¼"""
    try:
        enhanced_data = {}
        
        for i, df in enumerate(enhanced_dfs):
            asset_name = f"ASSET_{i}"  # å¯ä»¥æ ¹æ®éœ€è¦å‘½å
            enhanced_data[asset_name] = {
                'data': df.to_dict('records'),
                'index': df.index.strftime('%Y-%m-%d %H:%M:%S').tolist(),
                'columns': df.columns.tolist()
            }
        
        with open(json_path, 'w') as f:
            json.dump({
                'timestamp': time.time(),
                'data': enhanced_data,
                'metadata': {
                    'total_assets': len(enhanced_dfs),
                    'total_records': sum(len(df) for df in enhanced_dfs),
                    'features': list(enhanced_dfs[0].columns) if enhanced_dfs else [],
                    'data_type': 'real_stellar_data_with_features'
                }
            }, f, indent=2, default=str)
        
        print(f"    âœ… å¢å¼ºæ•°æ®å·²ä¿å­˜åˆ° {json_path}")
        
    except Exception as e:
        print(f"    âŒ ä¿å­˜å¢å¼ºæ•°æ®å¤±è´¥: {e}")

# â€”â€” ä¸»æµç¨‹ â€”â€” #

async def find_counter_asset(http: Http) -> Tuple[Optional[StellarAsset], StellarAsset]:
    """ä¼˜å…ˆå°è¯• USDC å‘è¡Œæ–¹ï¼›è‹¥æ— æ³•è§£æåˆ™å›é€€ XLM(native)ã€‚"""
    counter = await resolve_asset(http, COUNTER_PREFERRED)
    if counter is None:
        counter = StellarAsset.native()
    fallback = StellarAsset.native() if COUNTER_FALLBACK.upper() == "XLM" else await resolve_asset(http, COUNTER_FALLBACK)
    return counter, fallback

async def scrape_asset(http: Http, code: str, start_ms: int, end_ms: int, resolution: int,
                       counter_primary: StellarAsset, counter_fallback: StellarAsset) -> pd.DataFrame:
    base = await resolve_asset(http, code)
    if base is None:
        print(f"[WARN] Cannot resolve asset on Stellar: {code}")
        return pd.DataFrame()

    # å…ˆè¯• primary counterï¼ˆUSDCï¼‰ï¼Œä¸è¡Œå†è¯• XLM
    for counter in [counter_primary, counter_fallback]:
        try:
            rows = await fetch_trade_aggregations(http, base, counter, start_ms, end_ms, resolution)
            if rows:
                df = pd.DataFrame(rows)
                df["base_code"] = base.code
                df["base_issuer"] = base.issuer or ""
                df["counter_code"] = counter.code
                df["counter_issuer"] = counter.issuer or ""
                df["source"] = "stellar_dex"
                # å»é‡å¹¶æŒ‰æ—¶é—´æ’åº
                df = df.drop_duplicates(subset=["ts"]).sort_values("ts")
                return df
        except Exception as e:
            print(f"[INFO] {code} with counter {counter.code} failed: {e}")
            await asyncio.sleep(RATE_LIMIT_DELAY)

    print(f"[WARN] No trade_aggregations for {code} with USDC/XLM in last {LOOKBACK_DAYS}d")
    return pd.DataFrame()

async def main():
    os.makedirs(OUT_DIR, exist_ok=True)
    start_ms, end_ms = _last_30d_bounds()
    async with Http() as http:
        counter_primary, counter_fallback = await find_counter_asset(http)

        print(f"[INFO] Counter primary: {counter_primary.code} ({counter_primary.issuer or 'native'})")
        print(f"[INFO] Counter fallback: {counter_fallback.code} ({counter_fallback.issuer or 'native'})")
        print(f"[INFO] Time range: {datetime.fromtimestamp(start_ms/1000, tz=timezone.utc)} â†’ {datetime.fromtimestamp(end_ms/1000, tz=timezone.utc)}")
        print(f"[INFO] Resolution: {RESOLUTION_SEC} sec")

        all_dfs: List[pd.DataFrame] = []
        for code in TARGET_ASSETS:
            await asyncio.sleep(RATE_LIMIT_DELAY)
            df = await scrape_asset(http, code, start_ms, end_ms, RESOLUTION_SEC,
                                    counter_primary, counter_fallback)
            if df.empty:
                continue
            # ä¿å­˜æ¯èµ„äº§ CSV
            csv_path = os.path.join(OUT_DIR, f"stellar_ohlc_{RESOLUTION_SEC//60}m_{code}.csv")
            df.to_csv(csv_path, index=False)
            print(f"[OK] {code}: {len(df)} rows -> {csv_path}")
            all_dfs.append(df)

        if all_dfs:
            # ä¸ºæ¯ä¸ªèµ„äº§è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å’ŒMLç‰¹å¾
            enhanced_dfs = []
            for df in all_dfs:
                if not df.empty:
                    # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                    df = calculate_technical_indicators(df)
                    # åˆ›å»ºMLç‰¹å¾
                    df = create_ml_features(df)
                    enhanced_dfs.append(df)
            
            # ä¿å­˜å¢å¼ºæ•°æ®
            if enhanced_dfs:
                merged = pd.concat(enhanced_dfs, ignore_index=True)
                pq_path = os.path.join(OUT_DIR, f"stellar_ohlc_{RESOLUTION_SEC//60}m_all.parquet")
                merged.to_parquet(pq_path, index=False)
                print(f"[OK] enhanced parquet -> {pq_path}")
                
                # ä¿å­˜JSONæ ¼å¼ç”¨äºML/DL/RL
                json_path = os.path.join(OUT_DIR, "stellar_enhanced_data.json")
                save_enhanced_data(enhanced_dfs, json_path)
                print(f"[OK] enhanced JSON -> {json_path}")
        else:
            print("[WARN] No data collected. Check assets/issuers or expand fallback logic.")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass
